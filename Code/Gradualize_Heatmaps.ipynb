{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06604694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from utils import get_percentage_of_image, normalize_image\n",
    "import torch.nn.functional as F\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d13e157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/auswertung/convnext_tiny_test_NOSD/gradcam/test/\n"
     ]
    }
   ],
   "source": [
    "MODEL_TYPE = \"convnext_tiny_test_NOSD\"\n",
    "XAI_TYPE = \"gradcam\"\n",
    "BASE_DIR = \"data/\"\n",
    "DATASET = \"atsds_large\"\n",
    "DATASET_SPLIT = \"test\"\n",
    "GROUND_TRUTH_DIR = BASE_DIR + DATASET + \"_mask/\" + DATASET_SPLIT\n",
    "BACKGROUND_DIR = BASE_DIR + DATASET + \"_background/\" + DATASET_SPLIT\n",
    "DATASET_DIR = BASE_DIR + DATASET + \"/\" + DATASET_SPLIT\n",
    "XAI_DIR = BASE_DIR + \"auswertung/\" + MODEL_TYPE + \"/\" + XAI_TYPE + \"/\" + DATASET_SPLIT + \"/\"\n",
    "ADV_FOLDER = BASE_DIR + \"auswertung/\" + MODEL_TYPE + \"/\" + XAI_TYPE + \"/adversarial/\"\n",
    "print(XAI_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a6c762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00001', '00002', '00003', '00004', '00005', '00007', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00017', '00018', '00025', '00031', '00035', '00038']\n"
     ]
    }
   ],
   "source": [
    "IMAGES_PATH = 'data/' + DATASET + '/' + DATASET_SPLIT + '/'\n",
    "# Define our Categories\n",
    "CATEGORIES = sorted(os.listdir(IMAGES_PATH))\n",
    "print(CATEGORIES)\n",
    "class_to_dataset_class_dict = {}\n",
    "for cat in CATEGORIES:\n",
    "    class_to_dataset_class_dict[cat] = cat\n",
    "label_idx_dict = {}\n",
    "for count,cat in enumerate(CATEGORIES):\n",
    "    label_idx_dict[cat] = count\n",
    "\n",
    "imagedict = {}\n",
    "for cat in CATEGORIES:\n",
    "    imagedict[cat] = []\n",
    "    imagelist = os.listdir(IMAGES_PATH + cat + \"/\")\n",
    "    for im in imagelist:\n",
    "        imagedict[cat].append(im)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "543bf146",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pooling =torch.nn.AvgPool2d((129,129),stride = 1, padding=64,count_include_pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2f9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in CATEGORIES:\n",
    "    images = imagedict[cat]\n",
    "    if not os.path.isdir(XAI_DIR + cat + \"/grad_mask/\"):\n",
    "        os.makedirs(XAI_DIR + cat + \"/grad_mask/\" )\n",
    "    for imagename in images:\n",
    "        mask_raw = np.load(XAI_DIR + cat + \"/mask/\" + imagename + \".npy\")\n",
    "        mask = torch.Tensor(np.array(mask_raw)).unsqueeze(0).unsqueeze(0)\n",
    "        pooled_mask = avg_pooling(mask)\n",
    "        grad_mask = (normalize_image(np.array(mask_raw)) + normalize_image(pooled_mask.squeeze().squeeze().numpy())/100)\n",
    "        np.save(XAI_DIR + cat + \"/grad_mask/\" + imagename,grad_mask)\n",
    "        #save_mask = Image.fromarray(grad_mask*255).convert(\"L\")\n",
    "        #save_mask.save(XAI_DIR + cat + \"/grad_mask/\" + imagename)\n",
    "        #np.save(grad_mask)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0203889",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MULTI \n",
    "XAI_TYPES_MULTI = [\"lime\",\"gradcam\",\"prism\"]\n",
    "for current_xai in XAI_TYPES_MULTI:\n",
    "    XAI_DIR = BASE_DIR + \"auswertung/\" + MODEL_TYPE + \"/\" + current_xai + \"/\" + DATASET_SPLIT + \"/\"\n",
    "    for cat in CATEGORIES:\n",
    "        images = imagedict[cat]\n",
    "        if not os.path.isdir(XAI_DIR + cat + \"/grad_mask/\"):\n",
    "            os.makedirs(XAI_DIR + cat + \"/grad_mask/\" )\n",
    "        for imagename in images:\n",
    "            mask_raw = np.load(XAI_DIR + cat + \"/mask/\" + imagename + \".npy\")\n",
    "            mask = torch.Tensor(np.array(mask_raw)).unsqueeze(0).unsqueeze(0)\n",
    "            pooled_mask = avg_pooling(mask)\n",
    "            grad_mask = (normalize_image(np.array(mask_raw)) + normalize_image(pooled_mask.squeeze().squeeze().numpy())/100)\n",
    "            np.save(XAI_DIR + cat + \"/grad_mask/\" + imagename,grad_mask)\n",
    "            #save_mask = Image.fromarray(grad_mask*255).convert(\"L\")\n",
    "            #save_mask.save(XAI_DIR + cat + \"/grad_mask/\" + imagename)\n",
    "            #np.save(grad_mask)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ea10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
